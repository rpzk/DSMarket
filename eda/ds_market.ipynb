{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de vendas com calendário\n",
    "sales_calendar = dd.read_parquet('../data/sales_calendar/')\n",
    "# Carregar os dados de preços\n",
    "item_prices = dd.read_parquet('../data/prices/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter yearweek para string nos dois DataFrames\n",
    "sales_calendar['yearweek'] = sales_calendar['yearweek'].astype(str)\n",
    "item_prices['yearweek'] = item_prices['yearweek'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          id                 item     category_x  \\\n",
      "0  HOME_&_GARDEN_2_437_NYC_2  HOME_&_GARDEN_2_437  HOME_&_GARDEN   \n",
      "1  HOME_&_GARDEN_2_437_NYC_2  HOME_&_GARDEN_2_437  HOME_&_GARDEN   \n",
      "2    SUPERMARKET_1_052_NYC_2    SUPERMARKET_1_052    SUPERMARKET   \n",
      "3    SUPERMARKET_1_052_NYC_2    SUPERMARKET_1_052    SUPERMARKET   \n",
      "4    SUPERMARKET_1_053_NYC_2    SUPERMARKET_1_053    SUPERMARKET   \n",
      "\n",
      "        department   store store_code    region       d  sales yearweek  \\\n",
      "0  HOME_&_GARDEN_2  Harlem      NYC_2  New York  d_1053      0   201351   \n",
      "1  HOME_&_GARDEN_2  Harlem      NYC_2  New York  d_1053      0   201351   \n",
      "2    SUPERMARKET_1  Harlem      NYC_2  New York  d_1053      1   201351   \n",
      "3    SUPERMARKET_1  Harlem      NYC_2  New York  d_1053      1   201351   \n",
      "4    SUPERMARKET_1  Harlem      NYC_2  New York  d_1053      0   201351   \n",
      "\n",
      "        date event     category_y  sell_price  \n",
      "0 2013-12-16  <NA>  HOME_&_GARDEN      9.9625  \n",
      "1 2013-12-16  <NA>  HOME_&_GARDEN      9.9625  \n",
      "2 2013-12-16  <NA>    SUPERMARKET      1.1760  \n",
      "3 2013-12-16  <NA>    SUPERMARKET      1.1760  \n",
      "4 2013-12-16  <NA>    SUPERMARKET      6.5640  \n"
     ]
    }
   ],
   "source": [
    "# Fazer o merge dos DataFrames usando 'item', 'store_code', e 'yearweek' como chave\n",
    "merged_data = sales_calendar.merge(item_prices, on=['item', 'store_code', 'yearweek'], how='left')\n",
    "# Verificar as primeiras linhas do DataFrame resultante\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_parquet('../data/ds_market/', write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "item                 0\n",
       "category_x           0\n",
       "department           0\n",
       "store                0\n",
       "store_code           0\n",
       "region               0\n",
       "d                    0\n",
       "sales                0\n",
       "yearweek             0\n",
       "date                 0\n",
       "event         57561115\n",
       "category_y    12513532\n",
       "sell_price    12513532\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se há valores ausentes nas colunas principais\n",
    "missing_values = merged_data.isnull().sum().compute()\n",
    "print(\"Valores ausentes em cada coluna:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicatas com base em 'item', 'store_code', e 'yearweek'\n",
    "duplicates = merged_data.duplicated(subset=['item', 'store_code', 'yearweek']).compute()\n",
    "print(f\"Número de duplicatas: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descrever os dados para verificar os intervalos de valores\n",
    "print(merged_data[['sell_price', 'sales']].describe().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar objetos não utilizados e memória\n",
    "gc.collect()\n",
    "# Definir o caminho do diretório\n",
    "output_dir = '../data/merged_sales_with_calendar_and_prices'\n",
    "# Criar o diretório se ele não existir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Aumentar o número de partições se o arquivo ainda for muito grande\n",
    "merged_data_repartitioned = merged_data.repartition(npartitions=15)\n",
    "# Salvar as partições uma por vez (removendo 'write_index')\n",
    "for i, partition in enumerate(merged_data_repartitioned.to_delayed()):\n",
    "    partition.compute().to_parquet(f'{output_dir}/part_{i}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tamanho de cada partição\n",
    "print(merged_data_repartitioned.map_partitions(len).compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
