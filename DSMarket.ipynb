{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf10fa5-d8a8-4cd0-8b46-1e3788deb52e",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png\" alt=\"Image Title\">\n",
    "</p>\n",
    "\n",
    "# <p align=\"center\">Programa de mestrado Data Science & AI Nuclio Digital School</p>\n",
    "# <p align=\"center\">Nuclio Digital School</p>\n",
    "\n",
    "### Autores: **Bruno Matos, Henrique Salazar, Lucas Ferreira, Mário Sérgio, Rafael Piazenski, Tathiane Tioko**\n",
    "### Tutores: **Luís Roque, Tiago Otto Rogdrigues e João Pedro Correia dos Reis.**\n",
    "\n",
    "### Coordenador: **Rivadavia Padilha Vieira Junior**\n",
    "\n",
    "#### Data: ** **\n",
    "\n",
    "#### Prazo de Entrega: **20 de outubro de 2024.**\n",
    "\n",
    "#### Prazo de Defesa: ** **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2d6ee-17cb-43d3-a8f8-0c44cef94c48",
   "metadata": {},
   "source": [
    "# Índice\n",
    "1. [Introdução](#introdução)\n",
    "2. [Justificativa](#justificativa)\n",
    "3. [Objetivos](#objetivos)\n",
    "4. [Metodologia](#metodologia)\n",
    "5. [Resultados](#resultados)\n",
    "6. [Conclusões](#conclusões)\n",
    "7. [Bibliografia](#bibliografia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3074e93-696a-46e8-b4a8-eee34fe86c9a",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O caso DSMarket é apresentado como um exercício prático de _role play_, dividido em várias tarefas, proporcionando a execução passo a passo das etapas necessárias para obtenção do restuldado esperado.\n",
    "\n",
    "Este exercício prático tem como objetivo recriar um cenário de trabalho realista para um cientista de dados. O sucesso dos diferentes projetos muitas vezes dependerá da combinação dos três principais tipos de habilidades: programação, análise e negócios.\n",
    "\n",
    "Este projeto proporciona uma oportunidade de trabalhar em equipe, com os códigos dos colegas e com uso de ferramentas colaborativas que são frequentemente usadas em quase todos os projetos de Ciência de Dados.\n",
    "\n",
    "No papel de Nicole, uma Cientista de Dados Sênior que se junta ao departamento financeiro de uma pequena cadeia de centros comerciais: DSMarket, serão executadas essas etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a1426-1829-4368-a8b7-60574ace45ed",
   "metadata": {},
   "source": [
    "## Justificativa\n",
    "\n",
    "O objetivo deste projeto final de curso é proporcionar aos alunos uma imersão prática e aprofundada no campo de Data Science, equipando-os com as ferramentas teóricas e metodológicas necessárias para a execução de projetos complexos nesta área. Este projeto final serve como uma ponte entre a teoria e a prática, permitindo aos alunos aplicar os conhecimentos adquiridos ao longo do curso em situações reais, demonstrando sua capacidade de resolver problemas práticos e relevantes.\n",
    "\n",
    "Ao engajar-se nesse projeto, os alunos consolidam suas habilidades em análise de dados, modelagem estatística, machine learning e comunicação de resultados. A experiência prática adquirida é fundamental para prepará-los para os desafios do mercado de trabalho, promovendo uma compreensão robusta dos processos de desenvolvimento de projetos de Data Science, desde a concepção até a implementação e avaliação.\n",
    "\n",
    "Além disso, este projeto final oferece aos alunos a oportunidade de desenvolver competências essenciais para o trabalho em equipe, gestão de projetos e comunicação eficaz. Ao final do curso, os alunos terão não apenas aprofundado seus conhecimentos em tópicos específicos de Data Science, mas também terão construído um portfólio substancial de trabalho que poderá ser apresentado a futuros empregadores, destacando suas competências e realizações na área.\n",
    "\n",
    "Assim, o projeto final do curso de Data Science & AI da Nuclio Digital School, não apenas reforça a aprendizagem teórica dos alunos, mas também proporciona uma experiência prática inestimável, essencial para sua formação como profissionais competentes e inovadores em Data Science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e04b19-5ffe-44a0-9bda-7687b9dc788a",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "O objetivo principal desta tese é aplicar os conhecimentos e habilidades adquiridos ao longo do curso de Mestrado em Data Science & AI para resolver problemas reais em um cenário simulado. Especificamente, pretende-se:\n",
    "\n",
    "1. **Desenvolver habilidades práticas em Data Science:**\n",
    "   - Aplicar técnicas de programação, análise de dados e modelagem estatística para resolver problemas práticos no contexto do DSMarket.\n",
    "   - Desenvolver e implementar algoritmos de machine learning para análises preditivas e prescritivas.\n",
    "\n",
    "2. **Integrar conhecimentos multidisciplinares:**\n",
    "   - Combinar habilidades de programação, análise de dados e conhecimento de negócios para tomar decisões informadas e baseadas em dados.\n",
    "   - Demonstrar a capacidade de interpretar e comunicar resultados analíticos de maneira clara e concisa para stakeholders não técnicos.\n",
    "\n",
    "3. **Trabalhar com incertezas e requisitos ambíguos:**\n",
    "   - Navegar em ambientes com requisitos não completamente definidos, tomando decisões baseadas em dados e ajustando abordagens conforme necessário.\n",
    "   - Adaptar-se a cenários de incerteza, aplicando metodologias ágeis para iterar e melhorar soluções de forma contínua.\n",
    "\n",
    "4. **Desenvolver competências de trabalho em equipe e colaboração:**\n",
    "   - Colaborar efetivamente com colegas de equipe, integrando e utilizando códigos desenvolvidos por outros.\n",
    "   - Utilizar ferramentas colaborativas comuns em projetos de Data Science, como controle de versão e plataformas de gerenciamento de projetos.\n",
    "\n",
    "5. **Preparar-se para o mercado de trabalho:**\n",
    "   - Construir um portfólio de projetos que demonstre habilidades práticas em Data Science.\n",
    "   - Adquirir experiência prática em um ambiente simulado, preparando-se para enfrentar desafios reais no mercado de trabalho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2e1a4-6968-4e3c-970e-524f936146a2",
   "metadata": {},
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe238375",
   "metadata": {},
   "source": [
    "Processo de Criação da Tabela Final\n",
    "\n",
    "Inicamos com a consolidação de três diferentes bases de dados disponíveis em formato CSV, contendo informações de calendário, preços e vendas, em uma tabela unificada chamada ds_market. A seguir, descrevemos os principais passos realizados para alcançar a integração completa dos dados.\n",
    "\n",
    "1. Importação das Bases de Dados\n",
    "\n",
    "Inicialmente, realizamos a importação das três bases: daily_calendar_with_events.csv, item_prices.csv, e item_sales.csv. Essas bases foram carregadas utilizando a biblioteca Dask, devido ao grande volume de dados, o que facilitou o processamento de arquivos de grandes dimensões de forma distribuída. Cada uma dessas bases possui características específicas que precisaram ser adequadamente tratadas para garantir a consistência durante a integração.\n",
    "\n",
    "daily_calendar_with_events.csv: contém informações sobre as datas e eventos específicos, como feriados. Cada data é associada a um identificador d_x, que foi utilizado para fazer a correspondência com outras tabelas.\n",
    "item_prices.csv: armazena o histórico de preços dos itens por loja, categorizado por semanas (yearweek), código do item e loja (store_code).\n",
    "item_sales.csv: contém as vendas diárias por item, também organizadas por identificador d_x, loja e departamento.\n",
    "\n",
    "2. Processamento dos Dados\n",
    "\n",
    "Após a importação, foram realizadas algumas transformações essenciais para garantir a coerência e integridade das tabelas:\n",
    "\n",
    "Tratamento de Datas: Na tabela calendar, foi criada uma nova coluna yearweek, que representa a semana de cada data no formato ano-semana. Essa coluna foi essencial para realizar a sincronização com a tabela de preços e vendas, que utilizam yearweek para representar o período semanal.\n",
    "\n",
    "Tratamento de Valores Faltantes: Na tabela de preços (item_prices.csv), foram identificados valores ausentes na coluna yearweek, que precisaram ser preenchidos. Esse preenchimento foi realizado com base na sequência temporal de sell_price, ou seja, o valor da semana anterior foi replicado para preencher os valores faltantes.\n",
    "\n",
    "3. Unificação das Tabelas\n",
    "\n",
    "A integração dos dados foi realizada em duas etapas principais:\n",
    "\n",
    "Integração do Calendário com Vendas: Inicialmente, foi feito o mapeamento entre o calendário e a tabela de vendas. Utilizando o identificador d_x, foi possível unir as datas específicas às vendas diárias, agregando as informações de eventos e yearweek à tabela de vendas. Esse passo foi essencial para alinhar a granularidade temporal das duas tabelas.\n",
    "\n",
    "Integração com Preços: Em seguida, foi realizada a integração da tabela de vendas e calendário com a tabela de preços, utilizando como chave de ligação as colunas item, store_code, e yearweek. Esse procedimento garantiu que cada registro de vendas fosse associado ao preço correspondente daquele item na semana específica.\n",
    "\n",
    "4. Geração da Tabela Final\n",
    "\n",
    "A partir das integrações realizadas, a tabela final foi construída, contendo todas as informações necessárias para a análise de vendas e preços. A tabela resultante inclui as colunas de datas, preços, categorias de itens, eventos especiais (como feriados) e as vendas registradas, permitindo uma análise robusta do mercado.\n",
    "\n",
    "Tarefas e Papéis:\n",
    "\n",
    "    EDA (Exploratory Data Analysis):\n",
    "        Análise descritiva dos dados.\n",
    "        Limpeza e preparação dos dados.\n",
    "        Visualizações iniciais.\n",
    "    Clustering:\n",
    "        Pré-processamento dos dados para clustering.\n",
    "        Experimentação com diferentes algoritmos de clustering (K-means, DBSCAN, etc.).\n",
    "        Avaliação dos resultados usando métricas adequadas.\n",
    "\n",
    "Clustering de Produtos para Análise de Comportamento de Vendas\n",
    "Introdução ao Clustering Iniciamos a análise com o objetivo de agrupar produtos que apresentem comportamentos de venda semelhantes, utilizando técnicas de aprendizado não supervisionado. O agrupamento (ou clustering) permite segmentar produtos em grupos com características similares, facilitando a análise das vendas, campanhas de marketing e logística de estoque. Escolhemos essa abordagem para entender as semelhanças entre produtos e identificar tendências que possam variar entre as diferentes regiões de atuação da DSMarket.\n",
    "\n",
    "Metodologia de Clustering Para a execução do clustering, seguimos os seguintes passos:\n",
    "\n",
    "Pré-processamento dos Dados: Inicialmente, realizamos uma limpeza e preparação dos dados, normalizando variáveis numéricas para garantir que todas as features tivessem uma influência equilibrada na formação dos clusters. Isso incluiu a padronização de colunas como [incluir variáveis específicas usadas], essenciais para representar o comportamento de vendas dos produtos.\n",
    "\n",
    "Seleção de Variáveis e Algoritmo de Clustering: Selecionamos as variáveis mais relevantes que capturam o comportamento de venda de cada produto ao longo do tempo, como [especificar variáveis selecionadas], que foram então usadas como input para o algoritmo de clustering. O método K-means foi o escolhido inicialmente, pois permite uma segmentação clara e é adequado para identificar padrões em conjuntos de dados com grande quantidade de itens.\n",
    "\n",
    "Escolha do Número de Clusters: Utilizamos o método do cotovelo (elbow method) para determinar o número ideal de clusters. Observamos a soma dos erros quadráticos internos de cada cluster, buscando o ponto onde adicionar mais clusters deixava de reduzir significativamente o erro. Com essa abordagem, definimos que o número adequado de clusters era [incluir número de clusters].\n",
    "\n",
    "Avaliação dos Clusters: Para verificar a qualidade dos agrupamentos, calculamos o índice de Silhouette. Esse índice fornece uma medida de quão bem cada ponto está agrupado em relação aos pontos de outros clusters, variando de -1 (má definição) a 1 (definição ideal). Nosso resultado de Silhouette médio foi de [incluir resultado], o que indica que [incluir interpretação, por exemplo, “os grupos foram bem definidos e refletem padrões distintos de comportamento de vendas”].\n",
    "\n",
    "Resultados Após a aplicação do modelo de clustering, identificamos [resumo dos clusters com características principais de cada grupo, como alta/baixa demanda, sazonalidade, etc.]. Esses resultados indicam que os produtos se agrupam de forma natural em categorias distintas, o que oferece um ponto de partida sólido para campanhas de marketing e estratégias de estoque personalizadas.\n",
    "\n",
    "Discussão Os resultados do clustering oferecem insights valiosos para a DSMarket. A identificação de grupos de produtos com padrões de vendas similares permite ações direcionadas e melhora a alocação de recursos para marketing e logística. No próximo estágio, é possível expandir essa análise, testando outros algoritmos, como DBSCAN ou clustering hierárquico, para refinar ainda mais a segmentação dos produtos.\n",
    "\n",
    "    Forecasting:\n",
    "        Análise de séries temporais.\n",
    "        Escolha de modelos de previsão (ARIMA, Prophet, LSTM, etc.).\n",
    "        Validação dos modelos e previsão de vendas futuras.\n",
    "\n",
    "\n",
    "Aqui está o texto ajustado, refletindo o uso do modelo Prophet para previsão:\n",
    "\n",
    "Relatório de Previsão de Vendas para a DSMarket\n",
    "Introdução\n",
    "Este relatório apresenta os resultados do modelo de previsão de vendas para a DSMarket, com o objetivo de melhorar o planejamento de estoque, logística e as estratégias de reposição de produtos. As previsões foram realizadas para um horizonte de 28 dias (4 semanas) e cobrem os dados de lojas e produtos específicos. Através desta análise preditiva, buscamos reduzir os erros de estoque e otimizar a alocação de recursos.\n",
    "\n",
    "Metodologia\n",
    "\n",
    "Pré-processamento de Dados: O conjunto de dados foi processado para tratar valores ausentes, padronizar variáveis e normalizar dados temporais. Foram consideradas variáveis-chave como vendas históricas, categoria, preço e sazonalidade, que representam a demanda e comportamento de vendas ao longo do tempo.\n",
    "\n",
    "Modelo Utilizado: Para a previsão de vendas, o modelo Prophet foi escolhido, pois oferece uma abordagem robusta para captura de sazonalidades e tendências em séries temporais. Esse modelo é bem-sucedido em lidar com dados com padrão de alta frequência e consegue incorporar feriados, o que é vantajoso para dados de vendas com variação sazonal.\n",
    "\n",
    "Avaliação do Modelo: A precisão do Prophet foi avaliada usando métricas como:\n",
    "\n",
    "RMSE (Root Mean Squared Error): Varia entre 4.85 e 16.82 para os produtos e lojas analisados.\n",
    "MAE (Mean Absolute Error): As previsões apresentaram valores de MAE entre 3.71 e 12.39, indicando um desvio médio relativo baixo.\n",
    "MAPE (Mean Absolute Percentage Error): O MAPE variou de 17.47% a 82.02%, refletindo maior precisão em produtos de maior volume de vendas.\n",
    "A escolha do Prophet foi baseada na sua capacidade de lidar com a sazonalidade dos dados e fornecer uma previsão consistente ao longo do tempo.\n",
    "\n",
    "Resultados das Previsões\n",
    "Os resultados das previsões de vendas para o horizonte de 28 dias mostraram que o modelo Prophet apresentou desempenho consistente, com valores de erro médio absoluto (MAE) de 3.71 a 12.39 e MAPE entre 17.47% e 82.02%, indicando alta precisão em previsões semanais, especialmente para produtos e lojas de maior volume de vendas.\n",
    "\n",
    "Comparação entre Lojas e Produtos: As previsões foram realizadas para diversas lojas, com destaque para as cinco com maior volume de vendas. A loja Tribeca lidera com um total de 7.926 vendas previstas, seguida por Roxbury (6.717), Back Bay (5.942), Queen Village (5.753) e South End (4.893). Essas lojas demonstram uma demanda consistente, especialmente em produtos específicos que contribuem significativamente para as vendas totais.\n",
    "\n",
    "Entre os produtos mais vendidos, o item SUPERMARKET_3_090 apresenta o maior volume de vendas, com 12.603 vendas previstas, seguido pelo SUPERMARKET_3_586 (10.564), SUPERMARKET_3_252 (6.425), SUPERMARKET_3_555 (3.825) e SUPERMARKET_3_226 (3.489). Esses produtos têm um impacto relevante nas previsões gerais de vendas e são essenciais para a definição de estratégias de estoque e reposição.\n",
    "\n",
    "Discussão dos Resultados\n",
    "A aplicação do modelo Prophet nas previsões de vendas da DSMarket mostrou-se vantajosa, reduzindo a incerteza nas decisões de estoque e melhorando a previsão de demanda. Esse modelo foi eficiente na captura de padrões complexos nos dados, resultando em previsões mais precisas para produtos e lojas de alta relevância.\n",
    "\n",
    "Para futuros aprimoramentos, recomenda-se:\n",
    "\n",
    "Incorporar variáveis externas: como dados econômicos e campanhas de marketing, para melhorar a robustez das previsões.\n",
    "Implementar atualizações contínuas do modelo: usando dados mais recentes e ajustando os parâmetros conforme a demanda se altera.\n",
    "Conclusão\n",
    "Os resultados alcançados indicam que a previsão de vendas baseada no modelo Prophet pode ser uma ferramenta essencial para o planejamento estratégico da DSMarket. A implementação desse modelo permitirá que a empresa tome decisões informadas e melhore a eficiência de suas operações.\n",
    "\n",
    "Colaboração e Comunicação:\n",
    "\n",
    "    Utilize ferramentas como Slack ou Google Meet para comunicação rápida e eficiente.\n",
    "    Realize reuniões regulares para discutir o progresso e desafios.\n",
    "    Use issues no GitHub para gerenciar tarefas e bugs.\n",
    "\n",
    "Documentação:\n",
    "\n",
    "    Documente todos os passos e decisões tomadas durante o projeto.\n",
    "    Crie um relatório final com as descobertas e resultados de cada etapa (EDA, clustering, forecasting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc965a6-d2c7-4b53-ba49-ab19b7b0fafc",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ba0e1-3a8c-44a6-8887-02aa514d7c27",
   "metadata": {},
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389b084-9cc1-436e-a10d-112031744f54",
   "metadata": {},
   "source": [
    "## Bibliografia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
