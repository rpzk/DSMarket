{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4b6457",
   "metadata": {},
   "source": [
    "# Forecasting com Eventos (Incluindo Natal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c62af",
   "metadata": {},
   "source": [
    "## Importações e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b172585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rpiaz\\Desenvolvimento\\DSMarket\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Google Cloud Platform\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Bibliotecas para manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas para modelagem\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Importação do Prophet\n",
    "from prophet import Prophet\n",
    "\n",
    "# Configurar parâmetros de exibição\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633f826",
   "metadata": {},
   "source": [
    "## Conexão com o Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2daa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo de chave da conta de serviço\n",
    "service_account_path = 'tfm-sa.json'\n",
    "\n",
    "# Criar objeto de credenciais\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
    "\n",
    "# Configurações do projeto e dataset\n",
    "project_id = 'perseverance-332400'\n",
    "dataset_id = 'TFM'\n",
    "table_id = 'ds_market'\n",
    "full_table_id = f'{project_id}.{dataset_id}.{table_id}'\n",
    "\n",
    "# Criar cliente BigQuery\n",
    "client = bigquery.Client(project=project_id, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252a434",
   "metadata": {},
   "source": [
    "## Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfab1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rpiaz\\Desenvolvimento\\DSMarket\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir a consulta SQL para carregar os dados\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{full_table_id}`\n",
    "\"\"\"\n",
    "\n",
    "# Executar a consulta e carregar os dados em um DataFrame pandas\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee9a9a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Garantir que a coluna 'date' esteja em formato de data\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Definir a coluna 'date' como índice\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(\"Valores faltantes por coluna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3a563",
   "metadata": {},
   "source": [
    "## Inclusão do Evento \"Natal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_eventos(df):\n",
    "    if 'event' not in df.columns:\n",
    "        df['event'] = None\n",
    "    natal_dates = pd.to_datetime([\n",
    "        '2011-12-25', '2012-12-25', '2013-12-25',\n",
    "        '2014-12-25', '2015-12-25', '2016-12-25'\n",
    "    ])\n",
    "    df.loc[df.index.isin(natal_dates), 'event'] = 'Natal'\n",
    "    return df\n",
    "\n",
    "# Adicionar o evento \"Natal\"\n",
    "df = adicionar_eventos(df)\n",
    "\n",
    "# Codificar a coluna 'event' usando One-Hot Encoding, sem dummy_na\n",
    "df = pd.get_dummies(df, columns=['event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b392f",
   "metadata": {},
   "source": [
    "## Selecionar os Top 10 Itens Mais Vendidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as vendas totais por item\n",
    "top_items = df.groupby('item')['sales'].sum().sort_values(ascending=False).head(10).index\n",
    "\n",
    "# Filtrar o DataFrame para incluir apenas os top 10 itens\n",
    "df_top_items = df[df['item'].isin(top_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b3c42",
   "metadata": {},
   "source": [
    "## Análise por Loja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar uma loja específica (por exemplo, 'Queen_Village')\n",
    "store_name = 'Queen_Village'\n",
    "df_store = df_top_items[df_top_items['store'] == store_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf32d6",
   "metadata": {},
   "source": [
    "## Dados Diários e Preparação de Variáveis Exógenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e7ce3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Não agregue os dados; mantenha-os na frequência diária\n",
    "daily_sales = df_store.copy()\n",
    "\n",
    "# Identificar variáveis exógenas (eventos)\n",
    "exog_vars = [col for col in daily_sales.columns if 'event_' in col]\n",
    "\n",
    "# Não é necessário resetar o índice aqui, pois já o faremos depois\n",
    "\n",
    "# Separar ano e mês para facilitar\n",
    "daily_sales['year'] = daily_sales.index.year\n",
    "daily_sales['month'] = daily_sales.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e69bfe",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5792803",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def verificar_estacionariedade(series):\n",
    "    result = adfuller(series)\n",
    "    print('Estatística ADF:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    for key, value in result[4].items():\n",
    "        print('Critério {}: {}'.format(key, value))\n",
    "\n",
    "def preparar_variaveis_exogenas_futuras(exog_vars, start_date, periods, freq='D'):\n",
    "    future_dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n",
    "    future_exog = pd.DataFrame(index=future_dates)\n",
    "    for var in exog_vars:\n",
    "        future_exog[var] = 0  # Inicialmente zero\n",
    "    future_exog['event_Natal'] = 0\n",
    "    future_exog.loc[(future_exog.index.month == 12) & (future_exog.index.day == 25), 'event_Natal'] = 1\n",
    "    return future_exog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f8920",
   "metadata": {},
   "source": [
    "## Função para Treinar o Modelo SARIMAX e Fazer Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a2853",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_forecast(item_df, item_name):\n",
    "    # Configurar o índice de data\n",
    "    item_df = item_df.set_index('date')\n",
    "    \n",
    "    # Separar as variáveis exógenas (eventos)\n",
    "    exog_vars = [col for col in item_df.columns if 'event_' in col]\n",
    "    \n",
    "    # Dividir em treino e teste\n",
    "    train = item_df[item_df['year'] < 2016]\n",
    "    test = item_df[item_df['year'] == 2016]\n",
    "    \n",
    "    # Preparar as variáveis dependentes e independentes\n",
    "    y_train = train['sales']\n",
    "    X_train = train[exog_vars]\n",
    "    y_test = test['sales']\n",
    "    X_test = test[exog_vars]\n",
    "    \n",
    "    # Verificar estacionariedade\n",
    "    print(f'\\nVerificando estacionariedade para o item: {item_name}')\n",
    "    verificar_estacionariedade(y_train)\n",
    "    \n",
    "    # Selecionar o melhor modelo usando auto_arima\n",
    "    print(f'\\nSelecionando o melhor modelo para o item: {item_name}')\n",
    "    stepwise_fit = auto_arima(\n",
    "        y_train,\n",
    "        exogenous=X_train,\n",
    "        start_p=0, start_q=0,\n",
    "        max_p=3, max_q=3,\n",
    "        m=7,  # Sazonalidade semanal (dados diários)\n",
    "        seasonal=True,\n",
    "        d=1, D=1,\n",
    "        trace=False,\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True\n",
    "    )\n",
    "    \n",
    "    print(stepwise_fit.summary())\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = stepwise_fit.predict(n_periods=len(y_test), exogenous=X_test)\n",
    "    \n",
    "    # Avaliar o modelo\n",
    "    mse = ((y_pred - y_test.values) ** 2).mean()\n",
    "    mae = np.mean(np.abs(y_pred - y_test.values))\n",
    "    print(f'\\nItem: {item_name} - MSE: {mse:.2f}, MAE: {mae:.2f}')\n",
    "    \n",
    "    # Plotar resultados\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(y_train.index, y_train, label='Treino')\n",
    "    plt.plot(y_test.index, y_test, label='Teste')\n",
    "    plt.plot(y_test.index, y_pred, label='Previsão')\n",
    "    plt.title(f'Previsão de Vendas Diárias para {item_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Fazer previsão para os próximos 28 dias\n",
    "    future_exog = preparar_variaveis_exogenas_futuras(\n",
    "        exog_vars, start_date=y_test.index[-1] + pd.Timedelta(days=1), periods=28\n",
    "    )\n",
    "    future_forecast = stepwise_fit.predict(n_periods=28, exogenous=future_exog)\n",
    "    \n",
    "    # Criar DataFrame com as previsões futuras\n",
    "    future_dates = future_exog.index\n",
    "    forecast_df = pd.DataFrame({'date': future_dates, 'forecast': future_forecast})\n",
    "    forecast_df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Plotar previsões futuras\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(y_train.index, y_train, label='Treino')\n",
    "    plt.plot(y_test.index, y_test, label='Teste')\n",
    "    plt.plot(y_test.index, y_pred, label='Previsão')\n",
    "    plt.plot(forecast_df.index, forecast_df['forecast'], label='Previsão Futura')\n",
    "    plt.title(f'Previsão de Vendas Futura para {item_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Retornar as previsões futuras\n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff04c25",
   "metadata": {},
   "source": [
    "## Aplicar a Função para Cada Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário para armazenar as previsões futuras\n",
    "future_forecasts = {}\n",
    "\n",
    "for item in top_items:\n",
    "    print(f'\\nTreinando modelo para o item: {item}')\n",
    "    item_data = daily_sales[daily_sales['item'] == item].copy()\n",
    "    forecast = train_and_forecast(item_data, item)\n",
    "    future_forecasts[item] = forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d202a67",
   "metadata": {},
   "source": [
    "## Análise dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b8a55",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Exibir a previsão futura para um item específico\n",
    "item_to_view = top_items[0]  # Primeiro item da lista\n",
    "print(f'\\nPrevisão para os próximos 28 dias para o item {item_to_view}:')\n",
    "print(future_forecasts[item_to_view])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138646f",
   "metadata": {},
   "source": [
    "## Previsão com Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59fbcb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_forecast_prophet(data, item_name):\n",
    "    # Renomear as colunas para 'ds' e 'y' conforme esperado pelo Prophet\n",
    "    data = data.reset_index().rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "\n",
    "    # Converter 'ds' para datetime sem timezone\n",
    "    data['ds'] = pd.to_datetime(data['ds']).dt.tz_localize(None)\n",
    "\n",
    "    # Imprimir as colunas de data\n",
    "    print(\"Colunas em data:\", data.columns.tolist())\n",
    "\n",
    "    # Identificar variáveis exógenas e remover 'event_NaN' se existir\n",
    "    exog_vars = [col for col in data.columns if col.startswith('event_')]\n",
    "    print(\"Variáveis exógenas antes da filtragem:\", exog_vars)\n",
    "\n",
    "    # Remover 'event_nan' se estiver na lista\n",
    "    if 'event_nan' in exog_vars:\n",
    "        exog_vars.remove('event_nan')\n",
    "\n",
    "    print(\"Variáveis exógenas utilizadas:\", exog_vars)\n",
    "\n",
    "    # Garantir que as variáveis exógenas são numéricas e sem valores nulos\n",
    "    for var in exog_vars:\n",
    "        data[var] = pd.to_numeric(data[var], errors='coerce').fillna(0)\n",
    "\n",
    "    # Verificar tipos de dados e valores nulos\n",
    "    print(\"Tipos de dados das variáveis exógenas:\")\n",
    "    print(data[exog_vars].dtypes)\n",
    "    print(\"Valores nulos nas variáveis exógenas:\")\n",
    "    print(data[exog_vars].isnull().sum())\n",
    "\n",
    "    # Manter apenas as colunas necessárias\n",
    "    required_columns = ['ds', 'y'] + exog_vars\n",
    "    data = data[required_columns]\n",
    "\n",
    "    # Treinar o modelo\n",
    "    model = Prophet()\n",
    "\n",
    "    # Adicionar regressores\n",
    "    for var in exog_vars:\n",
    "        model.add_regressor(var)\n",
    "\n",
    "    # Treinar o modelo com os dados disponíveis\n",
    "    model.fit(data)\n",
    "\n",
    "    # Fazer previsões para os próximos 28 dias\n",
    "    future = model.make_future_dataframe(periods=28, freq='D')\n",
    "\n",
    "    # Adicionar variáveis exógenas futuras\n",
    "    for var in exog_vars:\n",
    "        future[var] = 0  # Inicialmente zero\n",
    "        if var == 'event_Natal':\n",
    "            future.loc[(future['ds'].dt.month == 12) & (future['ds'].dt.day == 25), var] = 1\n",
    "\n",
    "    # Verificar o DataFrame future\n",
    "    print(\"Colunas em future:\", future.columns.tolist())\n",
    "    print(\"Variáveis exógenas em future:\")\n",
    "    print(future[exog_vars].head())\n",
    "\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Plotar os resultados\n",
    "    model.plot(forecast)\n",
    "    plt.title(f'Previsão de Vendas para {item_name} usando Prophet')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotar componentes\n",
    "    model.plot_components(forecast)\n",
    "    plt.show()\n",
    "\n",
    "    # Retornar as previsões\n",
    "    return forecast[['ds', 'yhat']].set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c038ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a previsão com Prophet para um item\n",
    "print(f'\\nPrevisão com Prophet para o item: {item_to_view}')\n",
    "item_data = daily_sales[daily_sales['item'] == item_to_view].copy()\n",
    "forecast_prophet = train_and_forecast_prophet(item_data, item_to_view)\n",
    "\n",
    "# Salvar as previsões do Prophet\n",
    "forecast_prophet.to_csv(f'forecast_prophet_{item_to_view}.csv')\n",
    "print(f'Previsões com Prophet para {item_to_view} salvas em forecast_prophet_{item_to_view}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016bf4c",
   "metadata": {},
   "source": [
    "## Salvar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma lista para armazenar todos os DataFrames de previsão\n",
    "forecast_list = []\n",
    "\n",
    "for item, forecast_df in future_forecasts.items():\n",
    "    forecast_df = forecast_df.copy()\n",
    "    forecast_df['item'] = item\n",
    "    forecast_list.append(forecast_df)  # Adicionar o DataFrame à lista\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "all_forecasts = pd.concat(forecast_list, ignore_index=True)\n",
    "\n",
    "# Resetar o índice para facilitar a visualização\n",
    "all_forecasts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Salvar em um arquivo CSV\n",
    "all_forecasts.to_csv('all_forecasts.csv', index=False)\n",
    "print('Todas as previsões salvas em all_forecasts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2d373",
   "metadata": {},
   "source": [
    "# Interpretação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher um item para visualizar\n",
    "item_to_view = top_items[0]  # Primeiro item da lista\n",
    "print(f'\\nPrevisão para os próximos 28 dias para o item {item_to_view}:')\n",
    "print(future_forecasts[item_to_view])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
